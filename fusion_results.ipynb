{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hijuli66/33/blob/master/fusion_results.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 挂载 Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XqsaREKeGx1D",
        "outputId": "4583643e-b9d8-482a-e3b4-8d72c2095848"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 2. 在 33 整个目录下搜索所有 csv 文件\n",
        "!find \"/content/drive/MyDrive/33\" -type f -name \"*.csv\" 2>/dev/null\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tNfNvY_wIXGL",
        "outputId": "3cc5f4eb-9e23-439f-eaa9-e716c3cfd4bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/33/Images/QaTa-dataset/pair_table.csv\n",
            "/content/drive/MyDrive/33/Images/Models/images_features.csv\n",
            "/content/drive/MyDrive/33/Text/text_features.csv\n",
            "/content/drive/MyDrive/33/Text/keywords.csv\n",
            "/content/drive/MyDrive/33/Data/train.csv\n",
            "/content/drive/MyDrive/33/Data/val.csv\n",
            "/content/drive/MyDrive/33/Data/test.csv\n",
            "/content/drive/MyDrive/33/Data/test_predictions.csv\n",
            "/content/drive/MyDrive/33/Data/reports2.csv\n",
            "/content/drive/MyDrive/33/Data/reports1.csv\n",
            "/content/drive/MyDrive/33/Data/reports_merged.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 挂载 Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "# ==========================================\n",
        "# 阶段 0：安装必要的包\n",
        "# ==========================================\n",
        "print(\"阶段 0：正在安装依赖包...\")\n",
        "!pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu118 -q\n",
        "!pip install transformers sentence-transformers open-clip-torch ftfy scikit-learn -q\n",
        "print(\"阶段 0 完成：所有依赖包已安装\\n\")\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "\n",
        "# ==========================================\n",
        "# 阶段 1\n",
        "# ==========================================\n",
        "print(\"阶段 1：加载图像和文本特征文件...\")\n",
        "img_df = pd.read_csv(\"/content/drive/MyDrive/33/Images/Models/images_features.csv\")\n",
        "text_df = pd.read_csv(\"/content/drive/MyDrive/33/Text/text_features.csv\")\n",
        "print(\"加载完成，图像样本:\", len(img_df), \"文本样本:\", len(text_df))\n",
        "\n",
        "# 合并\n",
        "df = img_df.merge(text_df, on='image_id', how='inner', suffixes=('_img', '_text'))\n",
        "print(f\"成功配对样本数: {len(df)}\")\n",
        "\n",
        "# 正确选择列：图像特征、文本特征、图像的标签\n",
        "df = df[['image_id', 'feature_vector_img', 'feature_vector_text', 'label_img']]\n",
        "\n",
        "# 重命名\n",
        "df.rename(columns={\n",
        "    'feature_vector_img': 'img_vec',\n",
        "    'feature_vector_text': 'text_vec',\n",
        "    'label_img': 'label'\n",
        "}, inplace=True)\n",
        "\n",
        "print(\"最终使用的列名:\", df.columns.tolist())\n",
        "\n",
        "# 解析函数\n",
        "def str_to_vec(s, expected_dim):\n",
        "    if pd.isna(s):\n",
        "        return np.zeros(expected_dim, dtype=np.float32)\n",
        "    s = str(s).strip()\n",
        "    if s.startswith('['):\n",
        "        s = s[1:-1]  # 去掉可能的外层方括号\n",
        "    return np.fromstring(s, sep=',', dtype=np.float32)\n",
        "\n",
        "print(\"正在解析特征向量（约10-20秒）...\")\n",
        "df['img_vec'] = df['img_vec'].apply(lambda x: str_to_vec(x, 576))   # 图像特征是576维\n",
        "df['text_vec'] = df['text_vec'].apply(lambda x: str_to_vec(x, 768)) # 文本特征是768维\n",
        "\n",
        "# 检查解析是否成功\n",
        "print(\"第一条图像特征形状:\", df['img_vec'].iloc[0].shape)   # 应为 (576,)\n",
        "print(\"第一条文本特征形状:\", df['text_vec'].iloc[0].shape) # 应为 (768,)\n",
        "print(\"前5个图像特征值:\", df['img_vec'].iloc[0][:5])\n",
        "\n",
        "# 转为 numpy 并 L2 归一化（CLIP 类模型归一化）\n",
        "img_feats = np.stack(df['img_vec'].values)\n",
        "text_feats = np.stack(df['text_vec'].values)\n",
        "labels = df['label'].values.astype(np.float32)\n",
        "\n",
        "img_feats = img_feats / (np.linalg.norm(img_feats, axis=1, keepdims=True) + 1e-8)\n",
        "text_feats = text_feats / (np.linalg.norm(text_feats, axis=1, keepdims=True) + 1e-8)\n",
        "\n",
        "print(f\"最终特征形状 → 图像: {img_feats.shape} | 文本: {text_feats.shape} | 标签: {labels.shape}\")\n",
        "print(\"阶段 1 完成：数据加载、解析、归一化全部成功\\n\")\n",
        "\n",
        "# ==========================================\n",
        "# 阶段 2：智能划分（自动适配任意数据量）\n",
        "# ==========================================\n",
        "print(\"阶段 2：智能划分数据集（8:1:1）...\")\n",
        "train_val_idx, test_idx = train_test_split(np.arange(len(df)), test_size=0.1, random_state=42, stratify=labels)\n",
        "train_idx, val_idx = train_test_split(train_val_idx, test_size=0.1111, random_state=42, stratify=labels[train_val_idx])\n",
        "\n",
        "train_img, val_img, test_img = img_feats[train_idx], img_feats[val_idx], img_feats[test_idx]\n",
        "train_text, val_text, test_text = text_feats[train_idx], text_feats[val_idx], text_feats[test_idx]\n",
        "train_labels, val_labels, test_labels = labels[train_idx], labels[val_idx], labels[test_idx]\n",
        "\n",
        "print(f\"训练集: {len(train_idx)} | 验证集: {len(val_idx)} | 测试集: {len(test_idx)}\")\n",
        "print(\"阶段 2 完成\\n\")\n",
        "\n",
        "# ==========================================\n",
        "# 阶段 3：定义模型和数据加载器\n",
        "# ==========================================\n",
        "print(\"阶段 3：定义融合模型和 DataLoader...\")\n",
        "\n",
        "class SimpleFusion(nn.Module):\n",
        "    def __init__(self, img_dim=576, text_dim=768, hidden=512):\n",
        "        super().__init__()\n",
        "        self.proj_img = nn.Linear(img_dim, 256)\n",
        "        self.proj_text = nn.Linear(text_dim, 256)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(512, hidden),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(hidden, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, img_feat, text_feat):\n",
        "        i = self.proj_img(img_feat)\n",
        "        t = self.proj_text(text_feat)\n",
        "        fused = torch.cat([i, t], dim=-1)\n",
        "        return torch.sigmoid(self.classifier(fused))\n",
        "\n",
        "model = SimpleFusion().cuda()\n",
        "print(\"模型已定义并移到 GPU\")\n",
        "\n",
        "class MyDataset(Dataset):\n",
        "    def __init__(self, img_f, text_f, labels):\n",
        "        self.img_f = torch.tensor(img_f, dtype=torch.float32)\n",
        "        self.text_f = torch.tensor(text_f, dtype=torch.float32)\n",
        "        self.labels = torch.tensor(labels, dtype=torch.float32)\n",
        "    def __len__(self): return len(self.labels)\n",
        "    def __getitem__(self, idx): return self.img_f[idx], self.text_f[idx], self.labels[idx]\n",
        "\n",
        "train_dataset = MyDataset(train_img, train_text, train_labels)\n",
        "val_dataset   = MyDataset(val_img, val_text, val_labels)\n",
        "test_dataset  = MyDataset(test_img, test_text, test_labels)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "val_loader   = DataLoader(val_dataset, batch_size=128, shuffle=False)\n",
        "test_loader  = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
        "print(\"阶段 3 完成：模型和 DataLoader \\n\")\n",
        "\n",
        "# ==========================================\n",
        "# 阶段 4：训练模型（带早停）\n",
        "# ==========================================\n",
        "print(\"阶段 4：开始训练融合模型（最多 30 个 epoch，验证集 AUC 最高时保存）...\")\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "best_val_auc = 0\n",
        "best_model_path = \"/content/drive/MyDrive/33/Matching/best_fusion_model.pth\"\n",
        "\n",
        "for epoch in range(30):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    for i, t, l in tqdm(train_loader, desc=f\"Epoch {epoch+1}/30\"):\n",
        "        i, t, l = i.cuda(), t.cuda(), l.cuda().unsqueeze(1)\n",
        "        pred = model(i, t)\n",
        "        loss = criterion(pred, l)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    # 验证\n",
        "    model.eval()\n",
        "    val_preds, val_true = [], []\n",
        "    with torch.no_grad():\n",
        "        for i, t, l in val_loader:\n",
        "            i, t = i.cuda(), t.cuda()\n",
        "            pred = model(i, t).cpu().numpy()\n",
        "            val_preds.extend(pred.flatten())\n",
        "            val_true.extend(l.numpy())\n",
        "\n",
        "    val_auc = roc_auc_score(val_true, val_preds)\n",
        "    print(f\"Epoch {epoch+1:2d} | Train Loss: {train_loss/len(train_loader):.4f} | Val AUC: {val_auc:.4f}\")\n",
        "\n",
        "    if val_auc > best_val_auc:\n",
        "        best_val_auc = val_auc\n",
        "        torch.save(model.state_dict(), best_model_path)\n",
        "        print(\"保存最佳模型（当前最高 Val AUC）\")\n",
        "\n",
        "print(\"阶段 4 完成：训练结束，最佳模型已保存\\n\")\n",
        "\n",
        "# ==========================================\n",
        "# 阶段 5：加载最佳模型，在测试集上评估\n",
        "# ==========================================\n",
        "print(\"阶段 5：加载最佳模型，在测试集上进行最终评估\")\n",
        "model.load_state_dict(torch.load(best_model_path))\n",
        "model.eval()\n",
        "\n",
        "test_preds = []\n",
        "with torch.no_grad():\n",
        "    for i, t, l in tqdm(test_loader, desc=\"测试集推理\"):\n",
        "        i, t = i.cuda(), t.cuda()\n",
        "        pred = model(i, t).cpu().numpy()\n",
        "        test_preds.extend(pred.flatten())\n",
        "\n",
        "test_preds = np.array(test_preds)\n",
        "test_pred_label = (test_preds > 0.5).astype(int)\n",
        "\n",
        "model_auc = roc_auc_score(test_labels, test_preds)\n",
        "model_acc = accuracy_score(test_labels, test_pred_label)\n",
        "print(f\"模型在测试集上的 AUC: {model_auc:.4f} | Acc: {model_acc:.4f}\")\n",
        "print(\"阶段 5 完成\\n\")\n",
        "\n",
        "# ==========================================\n",
        "# 阶段 6：投影后余弦相似度 baseline\n",
        "# ==========================================\n",
        "print(\"阶段 6：使用训练好的投影层计算余弦相似度 baseline（投影到同一空间）...\")\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    # 把测试集特征转成 tensor 并移到 GPU\n",
        "    test_img_tensor  = torch.tensor(test_img,  dtype=torch.float32).cuda()\n",
        "    test_text_tensor = torch.tensor(test_text, dtype=torch.float32).cuda()\n",
        "\n",
        "    # 只用模型的前两层投影（不走分类头）\n",
        "    proj_img  = model.proj_img(test_img_tensor)   # (N, 256)\n",
        "    proj_text = model.proj_text(test_text_tensor) # (N, 256)\n",
        "\n",
        "    # L2 归一化后再计算余弦相似度（等价于点积）\n",
        "    proj_img  = torch.nn.functional.normalize(proj_img,  p=2, dim=1)\n",
        "    proj_text = torch.nn.functional.normalize(proj_text, p=2, dim=1)\n",
        "\n",
        "    cos_sim = (proj_img * proj_text).sum(dim=1).cpu().numpy()  # (N,)\n",
        "\n",
        "# 计算指标\n",
        "baseline_auc = roc_auc_score(test_labels, cos_sim)\n",
        "baseline_acc = accuracy_score(test_labels, (cos_sim > 0.0).astype(int))  # 投影后阈值通常接近0\n",
        "\n",
        "print(f\"【投影后余弦相似度 Baseline】 AUC: {baseline_auc:.4f} | Acc: {baseline_acc:.4f}\")\n",
        "print(\"阶段 6 完成\\n\")\n",
        "\n",
        "# ==========================================\n",
        "# 阶段 7：保存最终结果\n",
        "# ==========================================\n",
        "print(\"阶段 7：保存最终结果到 Google Drive...\")\n",
        "result_df = pd.DataFrame({\n",
        "    \"image_id\": df.iloc[test_idx]['image_id'].values,\n",
        "    \"similarity\": cos_sim,\n",
        "    \"fusion_confidence\": test_preds,\n",
        "    \"diagnosis\": test_pred_label,\n",
        "    \"true_label\": test_labels\n",
        "})\n",
        "result_df.to_csv(\"/content/drive/MyDrive/33/Matching/final_fusion_results.csv\", index=False)\n",
        "print(\"阶段 7 完成：最终结果已保存到 final_fusion_results.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LAIhhJmDbp_w",
        "outputId": "262638c9-2264-460e-e38a-8c0c3b0d5a36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "阶段 0：正在安装依赖包...\n",
            "阶段 0 完成：所有依赖包已安装\n",
            "\n",
            "阶段 1：加载图像和文本特征文件...\n",
            "加载完成，图像样本: 9219 文本样本: 9603\n",
            "成功配对样本数: 9219\n",
            "最终使用的列名: ['image_id', 'img_vec', 'text_vec', 'label']\n",
            "正在解析特征向量（约10-20秒）...\n",
            "第一条图像特征形状: (576,)\n",
            "第一条文本特征形状: (768,)\n",
            "前5个图像特征值: [0.48215514 0.5700968  0.36772284 0.97950566 0.8299695 ]\n",
            "最终特征形状 → 图像: (9219, 576) | 文本: (9219, 768) | 标签: (9219,)\n",
            "阶段 1 完成：数据加载、解析、归一化全部成功！\n",
            "\n",
            "阶段 2：智能划分数据集（8:1:1）...\n",
            "训练集: 7375 | 验证集: 922 | 测试集: 922\n",
            "阶段 2 完成\n",
            "\n",
            "阶段 3：定义融合模型和 DataLoader...\n",
            "模型已定义并移到 GPU\n",
            "阶段 3 完成：模型和 DataLoader \n",
            "\n",
            "阶段 4：开始训练融合模型（最多 30 个 epoch，验证集 AUC 最高时保存）...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/30: 100%|██████████| 116/116 [00:00<00:00, 379.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  1 | Train Loss: 0.0852 | Val AUC: 1.0000\n",
            "   → 保存最佳模型！（当前最高 Val AUC）\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/30: 100%|██████████| 116/116 [00:00<00:00, 367.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  2 | Train Loss: 0.0025 | Val AUC: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/30: 100%|██████████| 116/116 [00:00<00:00, 372.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  3 | Train Loss: 0.0012 | Val AUC: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/30: 100%|██████████| 116/116 [00:00<00:00, 390.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  4 | Train Loss: 0.0004 | Val AUC: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/30: 100%|██████████| 116/116 [00:00<00:00, 383.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  5 | Train Loss: 0.0001 | Val AUC: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/30: 100%|██████████| 116/116 [00:00<00:00, 373.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  6 | Train Loss: 0.0001 | Val AUC: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/30: 100%|██████████| 116/116 [00:00<00:00, 396.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  7 | Train Loss: 0.0000 | Val AUC: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/30: 100%|██████████| 116/116 [00:00<00:00, 392.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  8 | Train Loss: 0.0000 | Val AUC: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/30: 100%|██████████| 116/116 [00:00<00:00, 377.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  9 | Train Loss: 0.0000 | Val AUC: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/30: 100%|██████████| 116/116 [00:00<00:00, 392.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10 | Train Loss: 0.0000 | Val AUC: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11/30: 100%|██████████| 116/116 [00:00<00:00, 382.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11 | Train Loss: 0.0000 | Val AUC: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12/30: 100%|██████████| 116/116 [00:00<00:00, 375.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12 | Train Loss: 0.0000 | Val AUC: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13/30: 100%|██████████| 116/116 [00:00<00:00, 383.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13 | Train Loss: 0.0000 | Val AUC: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14/30: 100%|██████████| 116/116 [00:00<00:00, 384.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14 | Train Loss: 0.0000 | Val AUC: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15/30: 100%|██████████| 116/116 [00:00<00:00, 366.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15 | Train Loss: 0.0000 | Val AUC: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16/30: 100%|██████████| 116/116 [00:00<00:00, 386.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16 | Train Loss: 0.0000 | Val AUC: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17/30: 100%|██████████| 116/116 [00:00<00:00, 383.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17 | Train Loss: 0.0000 | Val AUC: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18/30: 100%|██████████| 116/116 [00:00<00:00, 312.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18 | Train Loss: 0.0000 | Val AUC: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19/30: 100%|██████████| 116/116 [00:00<00:00, 360.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19 | Train Loss: 0.0000 | Val AUC: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20/30: 100%|██████████| 116/116 [00:00<00:00, 375.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20 | Train Loss: 0.0000 | Val AUC: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 21/30: 100%|██████████| 116/116 [00:00<00:00, 377.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21 | Train Loss: 0.0000 | Val AUC: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 22/30: 100%|██████████| 116/116 [00:00<00:00, 382.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22 | Train Loss: 0.0000 | Val AUC: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 23/30: 100%|██████████| 116/116 [00:00<00:00, 376.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 23 | Train Loss: 0.0000 | Val AUC: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 24/30: 100%|██████████| 116/116 [00:00<00:00, 315.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 24 | Train Loss: 0.0000 | Val AUC: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 25/30: 100%|██████████| 116/116 [00:00<00:00, 307.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25 | Train Loss: 0.0000 | Val AUC: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 26/30: 100%|██████████| 116/116 [00:00<00:00, 309.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 26 | Train Loss: 0.0000 | Val AUC: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 27/30: 100%|██████████| 116/116 [00:00<00:00, 284.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 27 | Train Loss: 0.0000 | Val AUC: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 28/30: 100%|██████████| 116/116 [00:00<00:00, 307.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 28 | Train Loss: 0.0000 | Val AUC: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 29/30: 100%|██████████| 116/116 [00:00<00:00, 309.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 29 | Train Loss: 0.0000 | Val AUC: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 30/30: 100%|██████████| 116/116 [00:00<00:00, 265.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 30 | Train Loss: 0.0000 | Val AUC: 1.0000\n",
            "阶段 4 完成：训练结束，最佳模型已保存\n",
            "\n",
            "阶段 5：加载最佳模型，在测试集上进行最终评估\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "测试集推理: 100%|██████████| 8/8 [00:00<00:00, 510.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "模型在测试集上的 AUC: 1.0000 | Acc: 1.0000\n",
            "阶段 5 完成\n",
            "\n",
            "阶段 6：使用训练好的投影层计算余弦相似度 baseline（投影到同一空间）...\n",
            "【投影后余弦相似度 Baseline】 AUC: 0.0078 | Acc: 0.3970\n",
            "阶段 6 完成（这才是真正的强 baseline！）\n",
            "\n",
            "阶段 7：保存最终结果到 Google Drive...\n",
            "阶段 7 完成：最终结果已保存到 final_fusion_results.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# 只打印列名和样例数据（诊断专用）\n",
        "# ==========================================\n",
        "import pandas as pd\n",
        "\n",
        "print(\"正在读取图像特征文件...\")\n",
        "img_df = pd.read_csv(\"/content/drive/MyDrive/33/Images/Models/images_features.csv\")\n",
        "print(\"\\n【图像特征文件】列名：\")\n",
        "print(img_df.columns.tolist())\n",
        "print(\"\\n【图像特征文件】前 3 行完整数据：\")\n",
        "print(img_df.head(3))\n",
        "print(f\"\\n总行数：{len(img_df)}\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "print(\"正在读取文本特征文件...\")\n",
        "text_df = pd.read_csv(\"/content/drive/MyDrive/33/Text/text_features.csv\")\n",
        "print(\"\\n【文本特征文件】列名：\")\n",
        "print(text_df.columns.tolist())\n",
        "print(\"\\n【文本特征文件】前 3 行完整数据：\")\n",
        "print(text_df.head(3))\n",
        "print(f\"\\n总行数：{len(text_df)}\")\n",
        "print(\"=\" * 60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJq8AiDqdOZj",
        "outputId": "843e9285-9af1-4dd3-bdcc-f45e679ef96a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "正在读取图像特征文件...\n",
            "\n",
            "【图像特征文件】列名：\n",
            "['image_id', 'feature_vector', 'label']\n",
            "\n",
            "【图像特征文件】前 3 行完整数据：\n",
            "          image_id                                     feature_vector  label\n",
            "0  normal_4980.png  0.48215514,0.5700968,0.36772284,0.97950566,0.8...      0\n",
            "1  normal_4976.png  0.3330781,0.34160233,0.56426513,0.7748047,0.52...      0\n",
            "2  normal_4986.png  0.23818964,0.8397683,0.077592514,-0.03271132,0...      0\n",
            "\n",
            "总行数：9219\n",
            "------------------------------------------------------------\n",
            "正在读取文本特征文件...\n",
            "\n",
            "【文本特征文件】列名：\n",
            "['image_id', 'feature_vector', 'label']\n",
            "\n",
            "【文本特征文件】前 3 行完整数据：\n",
            "         image_id                                     feature_vector  label\n",
            "0   covid_424.png  0.16321910917758942,0.022436531260609627,-0.07...      1\n",
            "1  covid_4161.png  0.1978515386581421,0.10673397779464722,0.56492...      1\n",
            "2  covid_4188.png  0.025793712586164474,-0.401252806186676,-0.218...      1\n",
            "\n",
            "总行数：9603\n",
            "============================================================\n"
          ]
        }
      ]
    }
  ]
}